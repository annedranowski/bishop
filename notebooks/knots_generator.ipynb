{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cairosvg\n",
      "  Using cached CairoSVG-2.7.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting cairocffi (from cairosvg)\n",
      "  Using cached cairocffi-1.7.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting cssselect2 (from cairosvg)\n",
      "  Using cached cssselect2-0.7.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting defusedxml (from cairosvg)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting pillow (from cairosvg)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting tinycss2 (from cairosvg)\n",
      "  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cffi>=1.1.0 (from cairocffi->cairosvg)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting webencodings (from cssselect2->cairosvg)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pycparser (from cffi>=1.1.0->cairocffi->cairosvg)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Using cached CairoSVG-2.7.1-py3-none-any.whl (43 kB)\n",
      "Using cached cairocffi-1.7.1-py3-none-any.whl (75 kB)\n",
      "Using cached cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading pillow-11.1.0-cp312-cp312-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: webencodings, tinycss2, pycparser, pillow, defusedxml, cssselect2, cffi, cairocffi, cairosvg\n",
      "Successfully installed cairocffi-1.7.1 cairosvg-2.7.1 cffi-1.17.1 cssselect2-0.7.0 defusedxml-0.7.1 pillow-11.1.0 pycparser-2.22 tinycss2-1.4.0 webencodings-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install cairosvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import cairosvg\n",
    "from PIL import Image\n",
    "\n",
    "knots_count = [1, 0, 0, 1, 1, 2, 3, 7, 21, 49, 3] # number of knots with i crossings represented on the https://prideout.net/blog/svg_knots/knottable_v1.svg\n",
    "\n",
    "IMG_SIZE = 480 # size of the output image in px; influences on the complexity of the filling\n",
    "               # 480 is size of picture from our 801-knots database so we can use that one too\n",
    "\n",
    "# create and save the results\n",
    "save_dir = \"/content/new_knots_svg/\"\n",
    "try:\n",
    "    os.makedirs(save_dir)\n",
    "except FileExistsError:\n",
    "    print(f\"One or more directories in '{save_dir}' already exist.\")\n",
    "except PermissionError:\n",
    "    print(f\"Permission denied: Unable to create '{save_dir}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "save_dir = \"/content/new_knots_png/\"\n",
    "try:\n",
    "    os.makedirs(save_dir)\n",
    "except FileExistsError:\n",
    "    print(f\"One or more directories in '{save_dir}' already exist.\")\n",
    "except PermissionError:\n",
    "    print(f\"Permission denied: Unable to create '{save_dir}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "for cross_num in range(len(knots_count)):\n",
    "  for i in range(knots_count[cross_num]):\n",
    "    url = f\"https://prideout.net/blog/svg_knots/knots/{cross_num}_{i+1}.svg\"\n",
    "    full_path = f\"/content/new_knots_svg/{cross_num}_{i+1}.svg\"\n",
    "    urllib.request.urlretrieve(url, full_path)\n",
    "\n",
    "    # svg to png\n",
    "    cairosvg.svg2png(bytestring=open(f\"/content/new_knots_svg/{cross_num}_{i+1}.svg\", 'rb').read(), write_to=f\"/content/new_knots_png/{cross_num}_{i+1}.png\", output_width=IMG_SIZE, output_height=IMG_SIZE)\n",
    "\n",
    "    # fill png with white\n",
    "    bg = Image.new(\"RGBA\", (IMG_SIZE, IMG_SIZE), \"WHITE\")\n",
    "    fg = Image.open(f\"/content/new_knots_png/{cross_num}_{i+1}.png\")\n",
    "    bg.paste(fg, (0, 0), fg)\n",
    "    bg.save(f\"/content/new_knots_png/{cross_num}_{i+1}.png\")\n",
    "\n",
    "    # clear the image of errors\n",
    "    pixels_bg = bg.load()\n",
    "    img = Image.new(bg.mode, bg.size)\n",
    "    pixels = img.load()\n",
    "    for x in range(IMG_SIZE):\n",
    "      for y in range(IMG_SIZE):\n",
    "        if(x == 0 or y == 0 or x == IMG_SIZE-1 or y == IMG_SIZE-1):\n",
    "          pixels[x, y] = (255, 255, 255, 255)\n",
    "        else:\n",
    "          if(pixels_bg[x-1, y-1] == (0, 0, 0, 255) or\n",
    "             pixels_bg[x-1, y] == (0, 0, 0, 255) or\n",
    "             pixels_bg[x-1, y+1] == (0, 0, 0, 255) or\n",
    "             pixels_bg[x, y-1] == (0, 0, 0, 255) or\n",
    "             pixels_bg[x, y] == (0, 0, 0, 255) or\n",
    "             pixels_bg[x, y+1] == (0, 0, 0, 255) or\n",
    "             pixels_bg[x+1, y-1] == (0, 0, 0, 255) or\n",
    "             pixels_bg[x+1, y] == (0, 0, 0, 255) or\n",
    "             pixels_bg[x+1, y+1] == (0, 0, 0, 255)\n",
    "             ):\n",
    "            pixels[x, y] = (0, 0, 0, 255)\n",
    "          else:\n",
    "            pixels[x, y] = (255, 255, 255, 255)\n",
    "    img.save(f\"/content/new_knots_png/{cross_num}_{i+1}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def png_to_tensor(path : str =None, png_image : Image =None) -> torch.Tensor:\n",
    "  if(path != None):\n",
    "    png_image = Image.open(path)\n",
    "  transform = transforms.PILToTensor()\n",
    "  return transform(png_image)\n",
    "\n",
    "def tensor_to_png(tensor_image) -> Image:\n",
    "  transform = transforms.ToPILImage()\n",
    "  return transform(tensor_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helpers.py\").is_file():\n",
    "  print(\"helpers.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helpers.py\")\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/pytorch/vision/refs/heads/main/gallery/transforms/helpers.py\")\n",
    "  with open(\"helpers.py\", \"wb\") as f:\n",
    "    f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_to(str, num):\n",
    "  return \"0\"*(num-len(str)) + str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About uniformly distributed transformations**\n",
    "\n",
    "Suppose we have $N(m)$ knots with $m$ crossings, and $k$ available transformations. We want to know how many transformations we need to apply to get roughly the same amount of output knots. Let $n(m)$ be the number of transformed pictures for knot with $m$ crossings. The first and the naivest one can do to equitably distribute transforms is to abide by simple proportion: $n(m) \\cdot N(m) = n(j) \\cdot N(j) \\implies n(m) = n(j) \\frac{N(j)}{N(m)}$. Since the smallest possible value of $N$ is $1$ (obtainable at $m = 0, 3, 4$) and the maximum value of $n$ is $2^{k}$ we therefore can assume $n(0, 3, 4) = 2^{k}$. So, for each crossing number (and as we want every knot to be in the data) $i: n(m) = \\max(1, round(\\frac{2^{k}}{N(m)}))$ (given $j = 0$), where $round(x) = x, \\{x\\} < 0.5, [x]+1 \\ \\text{otherwise}$ where $\\{x\\}$ and $[x]$ are fractional and integer parts respectively.\n",
    "\n",
    "In the following considerations we will omit $m$ as we'll deal only with one particular number of crossings.\n",
    "Let $f_{i}$ be the number of $i$-th transform needed to be applied. We want to get uniformly distributed transformations, so ideal case is $f_i = f_j$. Let's use bit string $s$ where $i$-th bit represens whether the $i$-th transormation is applied or not. Thus, $f_i$ shows how many times we set $i$-th bit. So we cannot have diferent $f$'s since each $s$ requires us to define every bit so the values of $f$'s must be the same. Therefore, $f_i = n$.\n",
    "\n",
    "We want our $i$-th transform to be completely random, so $ p(0|s[i]) = \\frac{1}{2}$. Then we set $s[i] = 0$ in $\\lceil \\frac{f_i}{2} \\rceil$ cases and $s[i] = 1$ in $\\lfloor \\frac{f_i}{2} \\rfloor$ (we are also able to do it vice versa, but it doesn't give any impact and increase average runtime since it is biased to apply transformation).\n",
    "Suppose that at the $l$-th step we have $a$ cases $s[i] = 0$ left and $b$ respectively. Hence, we do not apply $i$-th transform and update $a = a - 1$ with probability $p(s[i] = 0) = \\frac{a}{a+b}$ and apply and update $b = b - 1$ with $p(s[i] = 0) = \\frac{b}{a+b}$.\n",
    "\n",
    "Doing that for each $s[i]$ we obtain completely random bit string $s$, thence we randomized application of transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply transforms to them!\n",
    "import os\n",
    "import math\n",
    "from torchvision.transforms import v2\n",
    "from helpers import plot\n",
    "import random\n",
    "\n",
    "# numbers of available transformations\n",
    "k = 6\n",
    "blurrer = v2.RandomRotation(degrees=(0, 180), expand=True, fill=255)\n",
    "plot([tensor_to_png(blurrer(png_to_tensor(\"/content/new_knots_png/4_1.png\")))])\n",
    "\n",
    "def save_transforms(filename, orig_dir):\n",
    "  try:\n",
    "    orig_img = png_to_tensor(path=orig_dir + filename + \".png\")\n",
    "  except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    return\n",
    "\n",
    "  # see https://pytorch.org/vision/0.20/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py\n",
    "\n",
    "  # random perspective\n",
    "  perspective_transformer = v2.RandomPerspective(distortion_scale=0.6, p=1.0, fill=255)\n",
    "\n",
    "  # random rotation\n",
    "  rotater = v2.RandomRotation(degrees=(0, 180), expand=True, fill=255)\n",
    "\n",
    "  # elastic\n",
    "  elastic_transformer = v2.ElasticTransform(alpha=250.0, fill=255)\n",
    "\n",
    "  # gaussian blur\n",
    "  blurrer = v2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.))\n",
    "\n",
    "  # horizontal flip\n",
    "  hflipper = v2.RandomHorizontalFlip(p=1)\n",
    "\n",
    "  # vertical flip\n",
    "  vflipper = v2.RandomVerticalFlip(p=1)\n",
    "\n",
    "  list_of_transforms = torch.nn.ModuleList([perspective_transformer, rotater, elastic_transformer, blurrer, hflipper, vflipper])\n",
    "\n",
    "  # create and save the results\n",
    "  save_dir = f\"/content/saved_knots/{filename}.png\"\n",
    "  try:\n",
    "      os.makedirs(save_dir)\n",
    "  except FileExistsError:\n",
    "      print(f\"One or more directories in '{save_dir}' already exist.\")\n",
    "  except PermissionError:\n",
    "      print(f\"Permission denied: Unable to create '{save_dir}'.\")\n",
    "      return\n",
    "  except Exception as e:\n",
    "      print(f\"An error occurred: {e}\")\n",
    "      return\n",
    "\n",
    "  # uniformly distributed transformations\n",
    "\n",
    "  # variables\n",
    "  m = int(filename.split('_')[0])\n",
    "  N = knots_count[m]\n",
    "  n = round(2**k/N)\n",
    "  s = [0]*k\n",
    "  in_s = []\n",
    "  a = [math.ceil(n/2)]*k\n",
    "  b = [math.floor(n/2)]*k\n",
    "\n",
    "  for i in range(n):\n",
    "    # set bits of s\n",
    "    for j in range(k):\n",
    "      rand_choice = random.randint(1, a[j]+b[j])\n",
    "      if rand_choice <= a[j]:\n",
    "        s[j] = 0\n",
    "        a[j] -= 1\n",
    "      else:\n",
    "        s[j] = 1\n",
    "        b[j] -= 1\n",
    "    in_s.append(int(''.join(str(j) for j in s), 2))\n",
    "\n",
    "    cur_img = orig_img\n",
    "    # for clarity of the image\n",
    "    if(s[0] or s[2]):\n",
    "      if(s[0]): cur_img = list_of_transforms[0](cur_img)\n",
    "      if(s[2]): cur_img = list_of_transforms[2](cur_img)\n",
    "\n",
    "      img = tensor_to_png(cur_img)\n",
    "      pixels = img.load()\n",
    "      img_cl = Image.new(img.mode, img.size)\n",
    "      pixels_cl = img_cl.load()\n",
    "      for x in range(IMG_SIZE):\n",
    "        for y in range(IMG_SIZE):\n",
    "          if(x == 0 or y == 0 or x == IMG_SIZE-1 or y == IMG_SIZE-1):\n",
    "            pixels_cl[x, y] = (255, 255, 255, 255)\n",
    "          else:\n",
    "            if(pixels[x-1, y-1] == (0, 0, 0, 255) or\n",
    "              pixels[x-1, y] == (0, 0, 0, 255) or\n",
    "              pixels[x-1, y+1] == (0, 0, 0, 255) or\n",
    "              pixels[x, y-1] == (0, 0, 0, 255) or\n",
    "              pixels[x, y] == (0, 0, 0, 255) or\n",
    "              pixels[x, y+1] == (0, 0, 0, 255) or\n",
    "              pixels[x+1, y-1] == (0, 0, 0, 255) or\n",
    "              pixels[x+1, y] == (0, 0, 0, 255) or\n",
    "              pixels[x+1, y+1] == (0, 0, 0, 255)\n",
    "              ):\n",
    "              pixels_cl[x, y] = (0, 0, 0, 255)\n",
    "            else:\n",
    "              pixels_cl[x, y] = (255, 255, 255, 255)\n",
    "      cur_img = png_to_tensor(png_image=img_cl)\n",
    "\n",
    "    for j in range(1, k):\n",
    "      if s[j] and j != 2:\n",
    "        cur_img = list_of_transforms[j](cur_img)\n",
    "\n",
    "    tensor_to_png(cur_img).save(save_dir + f\"/{filename}_{''.join(str(j) for j in s)}\" + f\"_{in_s.count(int(''.join(str(j) for j in s), 2))}.png\", \"png\")\n",
    "    saved_imgs.append(save_dir + f\"/{filename}_{''.join(str(j) for j in s)}\" + f\"_{in_s.count(int(''.join(str(j) for j in s), 2))}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "directory = os.fsencode(\"/content/new_knots_png\")\n",
    "\n",
    "# set -{number of knots you want to transform}\n",
    "N = 1\n",
    "\n",
    "saved_imgs = []\n",
    "\n",
    "# aka for knot_image in knots: save transforms of image\n",
    "for file in os.listdir(directory):\n",
    "    if(not N): break; N += 1\n",
    "    filename = os.path.splitext(os.fsdecode(file))[0]\n",
    "    save_transforms(str(filename), \"/content/new_knots_png/\")\n",
    "\n",
    "# save all to the .zip file\n",
    "with zipfile.ZipFile(\"knots_aug.zip\", \"w\") as saved_imgs_arch:\n",
    "    for imgname in saved_imgs:\n",
    "      saved_imgs_arch.write(imgname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
