{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0548f50d",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "Overview, explanation of the notebook/project.\n",
    "\n",
    "Action: Edit if needed to clarify your project’s purpose, goals, and high-level summary.\n",
    "\n",
    "    TODO: Let's move working models and helpers etc. from KG + Vanilla + CNN, Latest, etc. to this notebook.\n",
    "\n",
    "## Recommended Notebook Structure\n",
    "\n",
    "1. Title/Project Overview (Markdown)\n",
    "1. Environment & Imports\n",
    "1. Standard library and src/ imports\n",
    "1. (Optional) Colab Setup Cell\n",
    "1. Data Generation / Acquisition / Processing\n",
    "1. Downloading, generating, or preprocessing raw data\n",
    "1. Save processed data to a known location (set paths accordingly)\n",
    "1. Set Data Paths, Hyperparameters\n",
    "   * Now that you know where your data is and what shape it is, define paths, batch sizes, etc.\n",
    "1. Dataset and DataLoader Instantiation\n",
    "   * Use processed data and paths to instantiate dataset and dataloaders\n",
    "1. Model Instantiation\n",
    "1. Loss/Optimizer/Scheduler Setup\n",
    "1. Training Loop\n",
    "1. Evaluation Loop\n",
    "1. Visualization & Analysis\n",
    "1. Experiment Notes (Markdown)\n",
    "\n",
    "## General Annotation/Documentation Tips\n",
    "\n",
    "Top of Script: Use comments or module docstrings to describe the file’s overall purpose.\n",
    "\n",
    "Functions/Classes: Use docstrings as above. This is discoverable by IDEs, help() in Python, and documentation tools.\n",
    "\n",
    "Block Comments: Use inline comments (with #) to clarify tricky or non-obvious logic.\n",
    "\n",
    "Citations/Credits: Always include links or credits in the docstring, not just as comments before the class/function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0355107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from dataset import KnotDataset\n",
    "from models import VanillaNet, KnotCNN\n",
    "from train import train_step, train_loop\n",
    "from eval import test_step, eval_step, eval_loop # TODO: do we need to rename eval file? \n",
    "from utils import accuracy_fn\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "339ae54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# This cell selects the device\n",
    "import torch # TODO: do we need any imports in the notebook if we have requirements/environment files? \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "080d05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If in Colab, download data from GH or Google Drive\n",
    "# TODO: provide data download cells\n",
    "# E.g. If running in Google Colab\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Install dependencies\n",
    "    !pip install torch torchvision matplotlib pandas tqdm\n",
    "    # (Optional) Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb11f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths, hyperparameters (e.g., batch size, learning rate, num epochs)\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "train_data_path = '...'  # example\n",
    "# etc\n",
    "# Stay in the notebook: Parameter settings are high-level and may change between runs/experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42905aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class, image preprocessing, or DataLoader creation.\n",
    "# TODO: Move class/function definitions to src/dataset.py.\n",
    "# Keep only DataLoader instantiation (using imported class) in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f700fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class definition (VanillaNet, CNN, etc.)\n",
    "# TODO: Move model class definitions to src/models.py\n",
    "from models import KnotCNN\n",
    "# model = KnotCNN(...)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ac555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function, optimizer, scheduler definitions\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# TODO: Stay in the nb; optimizer/loss config is a high-level choice per experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a4018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_step, train_loop, test_step, eval_step, etc.\n",
    "from train import train_loop\n",
    "train_results = train_loop(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop or training call.\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # TODO\n",
    "# TODO: Keep only high-level function calls in the notebook (e.g., call train_loop).\n",
    "# Move any custom logic to src/train.py.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aa424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation/test logic, e.g., calling test_step or eval_loop\n",
    "# TODO: Just call the evaluation function from src/eval.py in the notebook\n",
    "# Plotting/visualization should remain in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf12b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization, plotting, analysis, Markdown cells explaining results.\n",
    "# TODO: This is your “report”/results space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
